{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bma-vandijk/VScode/whisper_welzijnAI/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Helper functions\n",
    "from utils.segment_audio import segment_audio_file\n",
    "from utils.convert_m4a_to_wav import convert_m4a_to_wav\n",
    "from utils.transcribe import transcribe_segments\n",
    "from utils.check_mono import check_and_convert_to_mono\n",
    "from utils.preprocess_gold_transcripts import process_gold_transcripts\n",
    "from utils.wer_evaluator import *\n",
    "from utils.counters import *\n",
    "from utils.postprocess_transcripts import TranscriptCleaner\n",
    "from utils.read_mozilla_dataset import create_orthographic_files,copy_audio_from_transcripts\n",
    "\n",
    "\n",
    "# Load WER metric|\n",
    "from evaluate import load\n",
    "\n",
    "# Read API key from .secrets/hf_api_key.txt\n",
    "with open(os.path.join('.secrets', 'hf_api_key.txt'), 'r') as file:\n",
    "    AUTH_TOKEN = file.read().strip()\n",
    "\n",
    "# List of Whisper models to use\n",
    "MODELS = [\n",
    "    \"golesheed/whisper-native-elderly-9-dutch\",\n",
    "    \"golesheed/whisper-9-dutch\",\n",
    "    \"golesheed/wav2vec2-xls-r-1b-dutch-3\",\n",
    "    \"golesheed/wav2vec2-xls-r-1b-dutch\",\n",
    "    \"openai/whisper-large-v3\",\n",
    "    \"openai/whisper-large-v2\",\n",
    "    \"openai/whisper-small\",\n",
    "    \"openai/whisper-medium\",\n",
    "    \"mistralai/Voxtral-Mini-3B-2507\",\n",
    "    \"openai/whisper-large-v3-turbo\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformat fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct filenames and formats\n",
    "for filename in os.listdir(RAW_DATA_DIR):\n",
    "    if filename == '.DS_Store':\n",
    "        continue\n",
    "    match = re.search(r'(\\d+)', filename)\n",
    "    if match:\n",
    "        number = match.group(1)\n",
    "        new_filename = f\"interaction_R{number}{os.path.splitext(filename)[1]}\"\n",
    "        old_path = os.path.join(RAW_DATA_DIR, filename)\n",
    "        new_path = os.path.join(RAW_DATA_DIR, new_filename)\n",
    "        os.rename(old_path, new_path)\n",
    "        convert_m4a_to_wav(new_filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain short segments of audio for each speaker from the original recordings in data/raw\n",
    "# Save in data/converted, do some manual cleanup afterwards and remove segments of Welzijn.AI bot or experimenter\n",
    "for filename in os.listdir(CONVERTED_DATA_DIR):\n",
    "            file_path = os.path.join(CONVERTED_DATA_DIR, filename)\n",
    "            segment_audio_file(file_path, OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert fragments to mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_and_convert_to_mono(os.path.join(OUTPUT_DIR, \"segments\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcribe fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n",
      "`return_token_timestamps` is deprecated for WhisperFeatureExtractor and will be removed in Transformers v5. Use `return_attention_mask` instead, as the number of frames can be inferred from it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribed interaction_R8_SPEAKER_01_seg_14.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R10_SPEAKER_01_seg_19.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R3_SPEAKER_00_seg_5.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R2_SPEAKER_01_seg_10.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_63.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R8_SPEAKER_01_seg_5.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_89.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_62.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R3_SPEAKER_00_seg_14.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R3_SPEAKER_00_seg_4.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R10_SPEAKER_01_seg_18.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R8_SPEAKER_01_seg_17.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R3_SPEAKER_00_seg_6.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R2_SPEAKER_01_seg_13.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R2_SPEAKER_01_seg_5.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R1_SPEAKER_01_seg_8.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_60.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_48.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R8_SPEAKER_01_seg_6.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R8_SPEAKER_01_seg_7.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_49.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_61.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R1_SPEAKER_01_seg_9.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_75.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R2_SPEAKER_01_seg_4.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R2_SPEAKER_01_seg_12.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R3_SPEAKER_00_seg_7.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R8_SPEAKER_01_seg_16.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R8_SPEAKER_01_seg_12.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R2_SPEAKER_01_seg_16.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R3_SPEAKER_00_seg_13.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_71.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_65.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R8_SPEAKER_01_seg_3.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R9_SPEAKER_00_seg_0.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R8_SPEAKER_01_seg_2.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_64.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R2_SPEAKER_01_seg_1.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R3_SPEAKER_00_seg_2.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R3_SPEAKER_00_seg_12.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R2_SPEAKER_01_seg_17.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R8_SPEAKER_01_seg_13.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R10_SPEAKER_01_seg_20.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R8_SPEAKER_01_seg_11.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R2_SPEAKER_01_seg_15.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R3_SPEAKER_00_seg_10.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R2_SPEAKER_01_seg_3.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_72.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_98.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_73.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R2_SPEAKER_01_seg_2.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R3_SPEAKER_00_seg_11.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R2_SPEAKER_01_seg_14.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R10_SPEAKER_01_seg_21.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R8_SPEAKER_01_seg_10.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R7_SPEAKER_00_seg_7.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R9_SPEAKER_01_seg_6.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_13.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R9_SPEAKER_01_seg_22.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R10_SPEAKER_01_seg_7.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R5_SPEAKER_01_seg_9.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R10_SPEAKER_01_seg_6.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_29.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R9_SPEAKER_01_seg_23.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_12.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R9_SPEAKER_01_seg_7.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R7_SPEAKER_00_seg_6.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_5.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_7.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R7_SPEAKER_00_seg_4.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R9_SPEAKER_01_seg_5.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_10.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R10_SPEAKER_01_seg_4.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R9_SPEAKER_01_seg_21.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R9_SPEAKER_01_seg_20.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R10_SPEAKER_01_seg_5.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_11.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R9_SPEAKER_01_seg_4.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R7_SPEAKER_00_seg_5.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_6.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_2.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R7_SPEAKER_00_seg_10.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_15.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R7_SPEAKER_00_seg_1.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R9_SPEAKER_01_seg_0.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_29.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R9_SPEAKER_01_seg_18.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R9_SPEAKER_01_seg_19.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R10_SPEAKER_01_seg_0.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R7_SPEAKER_00_seg_0.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_28.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R7_SPEAKER_00_seg_11.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_3.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R7_SPEAKER_00_seg_13.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R7_SPEAKER_00_seg_2.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_39.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R9_SPEAKER_01_seg_27.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R9_SPEAKER_01_seg_32.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_38.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R7_SPEAKER_00_seg_3.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_17.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R7_SPEAKER_00_seg_12.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_0.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R1_SPEAKER_00_seg_2.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R1_SPEAKER_01_seg_14.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R9_SPEAKER_01_seg_17.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R5_SPEAKER_01_seg_0.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R5_SPEAKER_01_seg_1.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_27.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_19.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_31.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R9_SPEAKER_01_seg_28.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_36.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R5_SPEAKER_01_seg_2.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R9_SPEAKER_01_seg_29.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_37.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R1_SPEAKER_01_seg_16.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_30.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_18.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_34.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_20.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R7_SPEAKER_00_seg_8.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R1_SPEAKER_01_seg_12.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R9_SPEAKER_01_seg_11.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R10_SPEAKER_01_seg_8.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R3_SPEAKER_01_seg_15.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R5_SPEAKER_01_seg_6.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R5_SPEAKER_01_seg_7.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R10_SPEAKER_01_seg_9.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_21.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R7_SPEAKER_00_seg_9.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R9_SPEAKER_01_seg_8.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_35.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_8.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R1_SPEAKER_01_seg_11.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R9_SPEAKER_01_seg_12.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_30.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R5_SPEAKER_01_seg_5.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R5_SPEAKER_01_seg_4.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R9_SPEAKER_01_seg_13.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R1_SPEAKER_01_seg_10.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_36.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_9.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R10_SPEAKER_01_seg_10.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R8_SPEAKER_01_seg_21.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R2_SPEAKER_01_seg_19.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R6_SPEAKER_01_seg_45.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_42.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_81.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_102.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_43.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R3_SPEAKER_00_seg_21.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R2_SPEAKER_01_seg_18.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R5_SPEAKER_01_seg_16.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R8_SPEAKER_01_seg_20.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R8_SPEAKER_01_seg_22.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R10_SPEAKER_01_seg_13.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R5_SPEAKER_01_seg_14.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_41.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_82.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_101.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_97.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_40.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_54.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R3_SPEAKER_00_seg_22.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R5_SPEAKER_01_seg_15.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R8_SPEAKER_01_seg_23.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R10_SPEAKER_01_seg_16.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R2_SPEAKER_01_seg_9.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_50.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_44.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_104.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_45.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_51.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R1_SPEAKER_01_seg_5.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R2_SPEAKER_01_seg_8.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R2_SPEAKER_01_seg_22.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R10_SPEAKER_01_seg_17.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R5_SPEAKER_01_seg_10.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R8_SPEAKER_01_seg_18.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R5_SPEAKER_01_seg_12.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R8_SPEAKER_01_seg_24.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R10_SPEAKER_01_seg_15.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R2_SPEAKER_01_seg_20.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R3_SPEAKER_00_seg_9.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_47.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_53.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R8_SPEAKER_01_seg_9.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_91.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_85.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R8_SPEAKER_01_seg_8.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_52.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R4_SPEAKER_01_seg_46.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R1_SPEAKER_01_seg_6.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R3_SPEAKER_00_seg_8.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R2_SPEAKER_01_seg_21.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R10_SPEAKER_01_seg_14.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R5_SPEAKER_01_seg_13.wav using openai/whisper-large-v3-turbo\n",
      "Transcribed interaction_R8_SPEAKER_01_seg_19.wav using openai/whisper-large-v3-turbo\n",
      "\n",
      "Timeout Summary:\n",
      "===============\n"
     ]
    }
   ],
   "source": [
    "# Check this, possibly due to updates on folders this may not work as expected\n",
    "transcribe_segments(MODELS[-1:], cpu=False, segments_dir=os.path.join('output', 'segments_beatrix'), output_transcript_dir=os.path.join('output', 'transcripts_beatrix'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre- and postprocess gold standard and output transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed files from: data/reference_transcripts_beatrix/orthographic\n",
      "  Orthographic_clean: data/reference_transcripts_beatrix/orthographic_clean\n",
      "  Normalized: data/reference_transcripts_beatrix/normalized\n",
      "  Normalized_clean: data/reference_transcripts_beatrix/normalized_clean\n"
     ]
    }
   ],
   "source": [
    "# Create different sets of GOLD/REFERENCE transcripts for different types of WER evaluation\n",
    "process_gold_transcripts(reference_folder=os.path.join('data', 'reference_transcripts_beatrix'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing existing output directory: output/transcripts_beatrix_cleaned\n",
      "Found 1990 transcript files to process\n",
      "Reading from: output/transcripts_beatrix\n",
      "Writing cleaned files to: output/transcripts_beatrix_cleaned\n",
      "Processed 100 files...\n",
      "Processed 200 files...\n",
      "Processed 300 files...\n",
      "Processed 400 files...\n",
      "Processed 500 files...\n",
      "Processed 600 files...\n",
      "Processed 700 files...\n",
      "Processed 800 files...\n",
      "Processed 900 files...\n",
      "Processed 1000 files...\n",
      "Processed 1100 files...\n",
      "Processed 1200 files...\n",
      "Processed 1300 files...\n",
      "Processed 1400 files...\n",
      "Processed 1500 files...\n",
      "Processed 1600 files...\n",
      "Processed 1700 files...\n",
      "Processed 1800 files...\n",
      "Processed 1900 files...\n",
      "Completed processing 1990 files\n",
      "Cleaned transcripts saved to: output/transcripts_beatrix_cleaned\n",
      "Original transcripts remain unchanged.\n"
     ]
    }
   ],
   "source": [
    "# Create one clean set of OUTPUT transcriptions without fillers, punctuation, capitals, trailing or leading whitespace\n",
    "cleaner = TranscriptCleaner()\n",
    "cleaner.process_directory(os.path.join(\"output\", \"transcripts_beatrix\"), os.path.join(\"output\", \"transcripts_beatrix_cleaned\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute WER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER for whisper-native-elderly-9-dutch: 0.41\n",
      "WER for whisper-9-dutch: 0.44\n",
      "WER for wav2vec2-xls-r-1b-dutch-3: 0.49\n",
      "WER for wav2vec2-xls-r-1b-dutch: 0.58\n",
      "WER for whisper-large-v3: 0.12\n",
      "WER for whisper-large-v2: 0.19\n",
      "WER for whisper-small: 0.26\n",
      "WER for whisper-medium: 0.19\n",
      "WER for Voxtral-Mini-3B-2507: 0.18\n"
     ]
    }
   ],
   "source": [
    "# Load WER metric\n",
    "wer_metric = load(\"wer\")\n",
    "\n",
    "# First the hardest gold/reference transcripts, 'orthographic'\n",
    "ref_orth = read_reference_transcripts(os.path.join('data', 'reference_transcripts_beatrix', 'orthographic'))\n",
    "\n",
    "for m in [m.split('/')[-1] for m in MODELS]:\n",
    "    wer = wer_metric.compute(references=ref_orth, predictions=read_asr_transcripts(os.path.join(\"output\", \"transcripts_beatrix\"))[m])\n",
    "    print(f\"WER for {m}: {wer:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER for whisper-native-elderly-9-dutch: 0.20\n",
      "WER for whisper-9-dutch: 0.25\n",
      "WER for wav2vec2-xls-r-1b-dutch-3: 0.43\n",
      "WER for wav2vec2-xls-r-1b-dutch: 0.54\n",
      "WER for whisper-large-v3: 0.34\n",
      "WER for whisper-large-v2: 0.37\n",
      "WER for whisper-small: 0.41\n",
      "WER for whisper-medium: 0.37\n",
      "WER for Voxtral-Mini-3B-2507: 0.37\n"
     ]
    }
   ],
   "source": [
    "# Load reference transcripts with punctuation and capitals removed.\n",
    "# This seems most fitting for Dutch Whisper model fine-tuned for older individuals, as it \n",
    "# does not predict punctuation and capitals, but does predict fillers\n",
    "ref_norm = read_reference_transcripts(os.path.join('data', 'reference_transcripts_beatrix', 'normalized'))\n",
    "\n",
    "for m in [m.split('/')[-1] for m in MODELS]:\n",
    "    wer = wer_metric.compute(references=ref_norm, predictions=read_asr_transcripts(os.path.join(\"output\", \"transcripts_beatrix\"))[m])\n",
    "    print(f\"WER for {m}: {wer:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER for whisper-native-elderly-9-dutch: 0.16\n",
      "WER for whisper-9-dutch: 0.20\n",
      "WER for wav2vec2-xls-r-1b-dutch-3: 0.36\n",
      "WER for wav2vec2-xls-r-1b-dutch: 0.46\n",
      "WER for whisper-large-v3: 0.06\n",
      "WER for whisper-large-v2: 0.10\n",
      "WER for whisper-small: 0.17\n",
      "WER for whisper-medium: 0.11\n",
      "WER for Voxtral-Mini-3B-2507: 0.10\n"
     ]
    }
   ],
   "source": [
    "# Load reference transcripts with punctuation and capitals removed.\n",
    "# This seems most fitting for Dutch Whisper model fine-tuned for older individuals, as it \n",
    "# does not predict punctuation and capitals, but does predict fillers\n",
    "ref_norm_clean = read_reference_transcripts(os.path.join('data', 'reference_transcripts_beatrix', 'normalized_clean'))\n",
    "\n",
    "for m in [m.split('/')[-1] for m in MODELS]:\n",
    "    wer = wer_metric.compute(references=ref_norm_clean, predictions=read_asr_transcripts(os.path.join(\"output\", \"transcripts_beatrix_cleaned\"))[m])\n",
    "    print(f\"WER for {m}: {wer:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words Orthographic: 2413\n",
      "Total words Normalized_clean: 1949\n",
      "Total minutes duration segments: 11.15\n"
     ]
    }
   ],
   "source": [
    "# What is the size of the dataset?\n",
    "print(f\"Total words Orthographic: {count_total_words(os.path.join('data', 'reference_transcripts_beatrix', 'orthographic'))}\")\n",
    "print(f\"Total words Normalized_clean: {count_total_words(os.path.join('data', 'reference_transcripts_beatrix', 'normalized_clean'))}\")\n",
    "print(f\"Total minutes duration segments: {get_total_audio_duration(os.path.join('output', 'segments_beatrix'))/60:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.345"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(11.15*60)/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05575"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11.15/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60*0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick experiment with Mozilla CV dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading/preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 transcript files\n",
      "Copied: common_voice_nl_41445352.mp3\n",
      "Copied: common_voice_nl_41445420.mp3\n",
      "Copied: common_voice_nl_26992952.mp3\n",
      "Copied: common_voice_nl_27120532.mp3\n",
      "Copied: common_voice_nl_20540645.mp3\n",
      "Copied: common_voice_nl_20541943.mp3\n",
      "Copied: common_voice_nl_28388257.mp3\n",
      "Copied: common_voice_nl_37256311.mp3\n",
      "Copied: common_voice_nl_39641321.mp3\n",
      "Copied: common_voice_nl_18322855.mp3\n",
      "Copied: common_voice_nl_28388331.mp3\n",
      "Copied: common_voice_nl_30520119.mp3\n",
      "Copied: common_voice_nl_41445418.mp3\n",
      "Copied: common_voice_nl_37249192.mp3\n",
      "Copied: common_voice_nl_41445906.mp3\n",
      "Copied: common_voice_nl_41445245.mp3\n",
      "Copied: common_voice_nl_18702069.mp3\n",
      "Copied: common_voice_nl_41445509.mp3\n",
      "Copied: common_voice_nl_41445323.mp3\n",
      "Copied: common_voice_nl_30505924.mp3\n",
      "Copied: common_voice_nl_20540623.mp3\n",
      "Copied: common_voice_nl_41445491.mp3\n",
      "Copied: common_voice_nl_28795644.mp3\n",
      "Copied: common_voice_nl_28795728.mp3\n",
      "Copied: common_voice_nl_41445890.mp3\n",
      "Copied: common_voice_nl_27149855.mp3\n",
      "Copied: common_voice_nl_28795648.mp3\n",
      "Copied: common_voice_nl_18702063.mp3\n",
      "Copied: common_voice_nl_28388404.mp3\n",
      "Copied: common_voice_nl_37256236.mp3\n",
      "Copied: common_voice_nl_19100076.mp3\n",
      "Copied: common_voice_nl_30544154.mp3\n",
      "Copied: common_voice_nl_28961103.mp3\n",
      "Copied: common_voice_nl_30403391.mp3\n",
      "Copied: common_voice_nl_37245662.mp3\n",
      "Copied: common_voice_nl_18695047.mp3\n",
      "Copied: common_voice_nl_28795664.mp3\n",
      "Copied: common_voice_nl_41445894.mp3\n",
      "Copied: common_voice_nl_37256231.mp3\n",
      "Copied: common_voice_nl_41445373.mp3\n",
      "Copied: common_voice_nl_28388328.mp3\n",
      "Copied: common_voice_nl_37245565.mp3\n",
      "Copied: common_voice_nl_30544122.mp3\n",
      "Copied: common_voice_nl_28796057.mp3\n",
      "Copied: common_voice_nl_30544132.mp3\n",
      "Copied: common_voice_nl_28388271.mp3\n",
      "Copied: common_voice_nl_37256253.mp3\n",
      "Copied: common_voice_nl_37256284.mp3\n",
      "Copied: common_voice_nl_27114705.mp3\n",
      "Copied: common_voice_nl_30505970.mp3\n",
      "Successfully copied 50 audio files to output/segments_mozilla\n"
     ]
    }
   ],
   "source": [
    "# Preprocess/load Mozilla CV\n",
    "create_orthographic_files(os.path.join('data', 'mozilla_cv', 'validated.tsv'), n_rows=50, seed=42)\n",
    "copy_audio_from_transcripts(os.path.join('data', 'reference_transcripts_mozilla', 'orthographic'), os.path.join('data','mozilla_cv','nl','clips'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribed common_voice_nl_30544154.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_19100076.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_37256236.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_18702063.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_28388404.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_27149855.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_28795648.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_28795728.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_41445890.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_41445894.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_37256231.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_28795664.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_18695047.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_37245662.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_30403391.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_28961103.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_30544122.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_28796057.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_37245565.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_28388328.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_41445373.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_30505970.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_27114705.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_28388271.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_37256253.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_37256284.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_30544132.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_28388257.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_20541943.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_20540645.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_27120532.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_26992952.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_41445420.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_41445352.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_30520119.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_37249192.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_41445418.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_28388331.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_18322855.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_39641321.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_37256311.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_41445509.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_18702069.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_41445906.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_41445245.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_28795644.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_41445491.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_30505924.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_20540623.mp3 using openai/whisper-large-v3-turbo\n",
      "Transcribed common_voice_nl_41445323.mp3 using openai/whisper-large-v3-turbo\n",
      "\n",
      "Timeout Summary:\n",
      "===============\n"
     ]
    }
   ],
   "source": [
    "transcribe_segments(MODELS[-1:], cpu=False, segments_dir=os.path.join('output', 'segments_mozilla'), output_transcript_dir=os.path.join('output', 'transcripts_mozilla'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed files from: data/reference_transcripts_mozilla/orthographic\n",
      "  Orthographic_clean: data/reference_transcripts_mozilla/orthographic_clean\n",
      "  Normalized: data/reference_transcripts_mozilla/normalized\n",
      "  Normalized_clean: data/reference_transcripts_mozilla/normalized_clean\n"
     ]
    }
   ],
   "source": [
    "# Create different sets of GOLD/REFERENCE transcripts for different types of WER evaluation\n",
    "process_gold_transcripts(os.path.join('data', 'reference_transcripts_mozilla'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing existing output directory: output/transcripts_mozilla_cleaned\n",
      "Found 500 transcript files to process\n",
      "Reading from: output/transcripts_mozilla\n",
      "Writing cleaned files to: output/transcripts_mozilla_cleaned\n",
      "Processed 100 files...\n",
      "Processed 200 files...\n",
      "Processed 300 files...\n",
      "Processed 400 files...\n",
      "Processed 500 files...\n",
      "Completed processing 500 files\n",
      "Cleaned transcripts saved to: output/transcripts_mozilla_cleaned\n",
      "Original transcripts remain unchanged.\n"
     ]
    }
   ],
   "source": [
    "# Create one clean set of OUTPUT transcriptions without fillers, punctuation, capitals, trailing or leading whitespace\n",
    "cleaner = TranscriptCleaner()\n",
    "cleaner.process_directory(os.path.join(\"output\", \"transcripts_mozilla\"), os.path.join(\"output\", \"transcripts_mozilla_cleaned\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WER evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER for whisper-native-elderly-9-dutch: 0.29\n",
      "WER for whisper-9-dutch: 0.31\n",
      "WER for wav2vec2-xls-r-1b-dutch-3: 0.29\n",
      "WER for wav2vec2-xls-r-1b-dutch: 0.32\n",
      "WER for whisper-large-v3: 0.07\n",
      "WER for whisper-large-v2: 0.08\n",
      "WER for whisper-small: 0.14\n",
      "WER for whisper-medium: 0.09\n",
      "WER for Voxtral-Mini-3B-2507: 0.08\n"
     ]
    }
   ],
   "source": [
    "# Load WER metric\n",
    "wer_metric = load(\"wer\")\n",
    "\n",
    "# First the hardest gold/reference transcripts, 'orthographic'\n",
    "ref_orth = read_reference_transcripts(os.path.join('data', 'reference_transcripts_mozilla', 'orthographic'))\n",
    "\n",
    "for m in [m.split('/')[-1] for m in MODELS]:\n",
    "    wer = wer_metric.compute(references=ref_orth, predictions=read_asr_transcripts(os.path.join(\"output\", \"transcripts_mozilla\"))[m])\n",
    "    print(f\"WER for {m}: {wer:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER for whisper-native-elderly-9-dutch: 0.09\n",
      "WER for whisper-9-dutch: 0.11\n",
      "WER for wav2vec2-xls-r-1b-dutch-3: 0.29\n",
      "WER for wav2vec2-xls-r-1b-dutch: 0.32\n",
      "WER for whisper-large-v3: 0.26\n",
      "WER for whisper-large-v2: 0.27\n",
      "WER for whisper-small: 0.32\n",
      "WER for whisper-medium: 0.28\n",
      "WER for Voxtral-Mini-3B-2507: 0.27\n"
     ]
    }
   ],
   "source": [
    "# Load reference transcripts with punctuation and capitals removed.\n",
    "# This seems most fitting for Dutch Whisper model fine-tuned for older individuals, as it \n",
    "# does not predict punctuation and capitals, but does predict fillers\n",
    "ref_norm = read_reference_transcripts(os.path.join('data', 'reference_transcripts_mozilla', 'normalized'))\n",
    "\n",
    "for m in [m.split('/')[-1] for m in MODELS]:\n",
    "    wer = wer_metric.compute(references=ref_norm, predictions=read_asr_transcripts(os.path.join(\"output\", \"transcripts_mozilla\"))[m])\n",
    "    print(f\"WER for {m}: {wer:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER for whisper-native-elderly-9-dutch: 0.09\n",
      "WER for whisper-9-dutch: 0.11\n",
      "WER for wav2vec2-xls-r-1b-dutch-3: 0.19\n",
      "WER for wav2vec2-xls-r-1b-dutch: 0.21\n",
      "WER for whisper-large-v3: 0.05\n",
      "WER for whisper-large-v2: 0.05\n",
      "WER for whisper-small: 0.11\n",
      "WER for whisper-medium: 0.07\n",
      "WER for Voxtral-Mini-3B-2507: 0.06\n",
      "WER for whisper-large-v3-turbo: 0.05\n"
     ]
    }
   ],
   "source": [
    "# Load reference transcripts with punctuation and capitals removed.\n",
    "# This seems most fitting for Dutch Whisper model fine-tuned for older individuals, as it \n",
    "# does not predict punctuation and capitals, but does predict fillers\n",
    "ref_norm_clean = read_reference_transcripts(os.path.join('data', 'reference_transcripts_mozilla', 'normalized_clean'))\n",
    "\n",
    "for m in [m.split('/')[-1] for m in MODELS]:\n",
    "    wer = wer_metric.compute(references=ref_norm_clean, predictions=read_asr_transcripts(os.path.join(\"output\", \"transcripts_mozilla_cleaned\"))[m])\n",
    "    print(f\"WER for {m}: {wer:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words Orthographic: 548\n",
      "Total words Normalized_clean: 488\n",
      "Total minutes duration segments: 4.44\n"
     ]
    }
   ],
   "source": [
    "# What is the size of the dataset?\n",
    "print(f\"Total words Orthographic: {count_total_words(os.path.join('data', 'reference_transcripts_mozilla', 'orthographic'))}\")\n",
    "print(f\"Total words Normalized_clean: {count_total_words(os.path.join('data', 'reference_transcripts_mozilla', 'normalized_clean'))}\")\n",
    "print(f\"Total minutes duration segments: {get_total_audio_duration(os.path.join('output', 'segments_mozilla'))/60:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiberon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>duration</th>\n",
       "      <th>transcription_time</th>\n",
       "      <th>RTF</th>\n",
       "      <th>WER</th>\n",
       "      <th>reference</th>\n",
       "      <th>hypothesis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>common_voice_nl_17695133</td>\n",
       "      <td>6.60</td>\n",
       "      <td>3</td>\n",
       "      <td>0.52</td>\n",
       "      <td>14.29</td>\n",
       "      <td>men kan geen ijzer met handen breken</td>\n",
       "      <td>men kan geen ijzer met hallen breken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>common_voice_nl_17695137</td>\n",
       "      <td>6.19</td>\n",
       "      <td>3</td>\n",
       "      <td>0.55</td>\n",
       "      <td>10.00</td>\n",
       "      <td>mijn trekrugzak woog achttien kilo toen we die...</td>\n",
       "      <td>mijn trekrugzak woog achttien kilo toen we die...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>common_voice_nl_17695138</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>waar zijn de toiletten</td>\n",
       "      <td>waar zijn de toiletten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>common_voice_nl_17695139</td>\n",
       "      <td>3.79</td>\n",
       "      <td>2</td>\n",
       "      <td>0.72</td>\n",
       "      <td>16.67</td>\n",
       "      <td>er komt pus uit de wonde</td>\n",
       "      <td>er komt pus uit de holde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>common_voice_nl_17695140</td>\n",
       "      <td>5.38</td>\n",
       "      <td>2</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ik neem altijd een drinkbus met water mee</td>\n",
       "      <td>ik neem altijd een drinkbus met water mee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   filename  duration  transcription_time   RTF    WER  \\\n",
       "0  common_voice_nl_17695133      6.60                   3  0.52  14.29   \n",
       "1  common_voice_nl_17695137      6.19                   3  0.55  10.00   \n",
       "2  common_voice_nl_17695138      3.98                   2  0.71   0.00   \n",
       "3  common_voice_nl_17695139      3.79                   2  0.72  16.67   \n",
       "4  common_voice_nl_17695140      5.38                   2  0.54   0.00   \n",
       "\n",
       "                                           reference  \\\n",
       "0               men kan geen ijzer met handen breken   \n",
       "1  mijn trekrugzak woog achttien kilo toen we die...   \n",
       "2                             waar zijn de toiletten   \n",
       "3                           er komt pus uit de wonde   \n",
       "4          ik neem altijd een drinkbus met water mee   \n",
       "\n",
       "                                          hypothesis  \n",
       "0              men kan geen ijzer met hallen breken   \n",
       "1  mijn trekrugzak woog achttien kilo toen we die...  \n",
       "2                            waar zijn de toiletten   \n",
       "3                           er komt pus uit de holde  \n",
       "4          ik neem altijd een drinkbus met water mee  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('results_elderly_60+.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>duration</th>\n",
       "      <th>transcription_time</th>\n",
       "      <th>RTF</th>\n",
       "      <th>WER</th>\n",
       "      <th>reference</th>\n",
       "      <th>hypothesis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>common_voice_nl_17695133</td>\n",
       "      <td>6.60</td>\n",
       "      <td>3</td>\n",
       "      <td>0.54</td>\n",
       "      <td>14.29</td>\n",
       "      <td>men kan geen ijzer met handen breken</td>\n",
       "      <td>men kan geen ijzer met hallen breken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>common_voice_nl_17695137</td>\n",
       "      <td>6.19</td>\n",
       "      <td>3</td>\n",
       "      <td>0.53</td>\n",
       "      <td>10.00</td>\n",
       "      <td>mijn trekrugzak woog achttien kilo toen we die...</td>\n",
       "      <td>mijn trekrugzak woog 18 kilo toen we die trek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>common_voice_nl_17695138</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>waar zijn de toiletten</td>\n",
       "      <td>waar zijn de toiletten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>common_voice_nl_17695139</td>\n",
       "      <td>3.79</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>16.67</td>\n",
       "      <td>er komt pus uit de wonde</td>\n",
       "      <td>er komt pus uit de wollen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>common_voice_nl_17695140</td>\n",
       "      <td>5.38</td>\n",
       "      <td>2</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ik neem altijd een drinkbus met water mee</td>\n",
       "      <td>ik neem altijd een drinkbus met water mee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   filename  duration  transcription_time   RTF    WER  \\\n",
       "0  common_voice_nl_17695133      6.60                   3  0.54  14.29   \n",
       "1  common_voice_nl_17695137      6.19                   3  0.53  10.00   \n",
       "2  common_voice_nl_17695138      3.98                   2  0.69   0.00   \n",
       "3  common_voice_nl_17695139      3.79                   2  0.75  16.67   \n",
       "4  common_voice_nl_17695140      5.38                   2  0.54   0.00   \n",
       "\n",
       "                                           reference  \\\n",
       "0               men kan geen ijzer met handen breken   \n",
       "1  mijn trekrugzak woog achttien kilo toen we die...   \n",
       "2                             waar zijn de toiletten   \n",
       "3                           er komt pus uit de wonde   \n",
       "4          ik neem altijd een drinkbus met water mee   \n",
       "\n",
       "                                          hypothesis  \n",
       "0               men kan geen ijzer met hallen breken  \n",
       "1   mijn trekrugzak woog 18 kilo toen we die trek...  \n",
       "2                             waar zijn de toiletten  \n",
       "3                          er komt pus uit de wollen  \n",
       "4          ik neem altijd een drinkbus met water mee  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('results_v2_60+.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
